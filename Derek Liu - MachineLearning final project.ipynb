{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part 1:  get the model\n",
    "- __Features(categorical): every unique word in all descriptions of groups. eg: ['this']['is']['fight']['club']...__\n",
    "- __Labels: Group categories__\n",
    "\n",
    "#### Goal: Train my model to classify a group based on the description of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from urllib.request import urlopen \n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from pyspark import SparkContext\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cleaner(descrips):\n",
    "    \n",
    "    'clean the description and return a list of strings'\n",
    "    \n",
    "    # get rid of str between < >\n",
    "    delirm = re.sub('<[^>]+>', '', str(descrips))\n",
    "    # get rid of symbols\n",
    "    l = re.findall(r\"[\\w']+\", str(delirm))\n",
    "    return list(filter(lambda a: len(a) > 2, l))\n",
    "\n",
    "def cleaner2(descrips):\n",
    "    # remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    return [word for word in descrips if word not in stops]\n",
    "        \n",
    "\n",
    "\n",
    "def combiner(words):\n",
    "    \n",
    "    'combine list of string back to a sentence'\n",
    "    \n",
    "    return ' '.join(word for word in words)\n",
    "\n",
    "\n",
    "def indexer_vocabs(list_of_event):\n",
    "    \n",
    "    'return a list of cleaned sentence and a list of vocabulary'\n",
    "    \n",
    "    myindex = []\n",
    "    allwords = []\n",
    "    for line in list_of_event:\n",
    "        list_of_words = cleaner2(cleaner(line))\n",
    "        allwords += list_of_words\n",
    "        element = combiner(list_of_words)\n",
    "        myindex.append(element)\n",
    "    return myindex, list(set(allwords))\n",
    "\n",
    "\n",
    "def getDF(ind, col):\n",
    "    return pd.DataFrame(index=ind, columns=col)\n",
    "\n",
    "\n",
    "def converToArray(df, col):\n",
    "    for i in range(df.shape[0]):\n",
    "        for word in col:\n",
    "            df.ix[i, str(word)] = df.index[i].count(str(word))\n",
    "    return np.array(df)\n",
    "\n",
    "\n",
    "def getshortname(ss):\n",
    "    \n",
    "    if ss is None:\n",
    "        return 'None'\n",
    "    elif ss.asDict().get('category') is None:\n",
    "        return 'None'\n",
    "    elif ss.asDict().get('category').asDict().get('shortname') is None:\n",
    "        return 'None'\n",
    "    return ss.asDict().get('category').asDict().get('shortname')\n",
    "\n",
    "\n",
    "def getcountry(ss):\n",
    "    \n",
    "    if ss is None:\n",
    "        return 'None'\n",
    "    elif ss.asDict().get('country') is None:\n",
    "        return 'None'\n",
    "    return ss.asDict().get('country')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "txt = spark.read.json('/Users/DL/Desktop/DL-Projects-master/meetup group/2017/*/*/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- description: string (nullable = true)\n",
      " |-- duration: long (nullable = true)\n",
      " |-- event_url: string (nullable = true)\n",
      " |-- fee: struct (nullable = true)\n",
      " |    |-- amount: double (nullable = true)\n",
      " |    |-- currency: string (nullable = true)\n",
      " |    |-- description: string (nullable = true)\n",
      " |-- group: struct (nullable = true)\n",
      " |    |-- category: struct (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- shortname: string (nullable = true)\n",
      " |    |-- city: string (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- group_lat: double (nullable = true)\n",
      " |    |-- group_lon: double (nullable = true)\n",
      " |    |-- group_photo: struct (nullable = true)\n",
      " |    |    |-- highres_link: string (nullable = true)\n",
      " |    |    |-- photo_id: long (nullable = true)\n",
      " |    |    |-- photo_link: string (nullable = true)\n",
      " |    |    |-- thumb_link: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- join_mode: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- state: string (nullable = true)\n",
      " |    |-- urlname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- maybe_rsvp_count: long (nullable = true)\n",
      " |-- mtime: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- payment_required: string (nullable = true)\n",
      " |-- rsvp_limit: long (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- utc_offset: long (nullable = true)\n",
      " |-- venue: struct (nullable = true)\n",
      " |    |-- address_1: string (nullable = true)\n",
      " |    |-- address_2: string (nullable = true)\n",
      " |    |-- city: string (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- lat: double (nullable = true)\n",
      " |    |-- lon: double (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- phone: string (nullable = true)\n",
      " |    |-- state: string (nullable = true)\n",
      " |    |-- zip: string (nullable = true)\n",
      " |-- venue_visibility: string (nullable = true)\n",
      " |-- visibility: string (nullable = true)\n",
      " |-- yes_rsvp_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = txt.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(category=Row(id=34, name='tech', shortname='tech'), city='Chicago', country='us', group_lat=41.89, group_lon=-87.64, group_photo=None, id=23065697, join_mode='open', name='Chicago Deep Learning PB-Scale AI Big Data Cloud Boot Camp', state='IL', urlname='Chicago-Deep-Learning-PBScale-AI-Big-Data-Cloud-IoT-BootCamp')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw data sample\n",
    "df['group'][900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "descriptions = list(df['description'])\n",
    "gplist = list(map(getshortname, df['group']))\n",
    "countrylist = list(map(getcountry, df['group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_table = pd.DataFrame(\n",
    "    {'descriptions': descriptions,\n",
    "     'group': gplist,\n",
    "     'country': countrylist\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only doing events in US, so descriptions will only be in English\n",
    "new_table = new_table[new_table.country == 'us']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>us</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://www.eventbrite.com/e/kdb-h...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>us</td>\n",
       "      <td>None</td>\n",
       "      <td>food-drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>us</td>\n",
       "      <td>&lt;p&gt;No big field game this weekend !&amp;nbsp;&lt;/p&gt; ...</td>\n",
       "      <td>sports-recreation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country                                       descriptions  \\\n",
       "31      us  <p><a href=\"https://www.eventbrite.com/e/kdb-h...   \n",
       "40      us                                               None   \n",
       "45      us  <p>No big field game this weekend !&nbsp;</p> ...   \n",
       "\n",
       "                group  \n",
       "31               tech  \n",
       "40         food-drink  \n",
       "45  sports-recreation  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new_table.shape)\n",
    "new_table.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13500"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_list = list(new_table['descriptions'])\n",
    "len(des_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__I only need the desciptions to build my feature matrix. As I noticed there is a person's NAME in the description. This could be very helpful for prediction.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13500 57159\n"
     ]
    }
   ],
   "source": [
    "ind, vocabs = indexer_vocabs(des_list)\n",
    "print(len(ind), len(vocabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Last Meetup worked system diagram spilt ownership clearly see saw progress understanding audio input PS4 mic array able see great rendering drone simulation PX4 Gazebo React etc you're engineer enthusiast interested helping build program curious welcome nbsp Planning small beer must yrs age option Bring laptops spare drone parts you'd like see given new life feel free email anytime add active Slack group masked nbsp please clearly tell want join nonoisedrone's slack channel\""
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.asarray(new_table['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(vocabulary=vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DL/anaconda3/envs/dsci6007/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# get the frequency table\n",
    "X=cv.fit_transform(ind).toarray()\n",
    "x_update = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dancing', 'arts-culture', 'new-age-spirituality', ..., 'games',\n",
       "       'outdoors-adventure', 'tech'], \n",
       "      dtype='<U21')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = clf.predict(x_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56000000000000005"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the result of not applying normalization. With normalization, the score is even lower. \n",
    "prediction = sum(result == y_test)/float(len(y_test))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "          learning_rate=1.0, n_estimators=30, random_state=None)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=MultinomialNB(),\n",
    "                        n_estimators =30)\n",
    "\n",
    "ada.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04925925925925926"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The score is extreming bad. Checking if y_test contains any categories that are not in y-train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_test) == set(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part 2: takeaway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Since I am using all categorical features, Naive baye's is definitly the optimal classifier in this case. However, it is a little different from the NB praticum; my labels have multiple categories, therefore, I used Multinomial Naive baye's.__\n",
    "\n",
    "__Observation from my data, the group description is constantly changing for the same group, this can result an inconsistancy, in which case my model might get confused. Secondly, many descriptions of the group are completely unrelated to the group category, this can be a big issue as my model might not be able to capture the randomness. Maybe increasing the amount of data can help minimize this problem.__\n",
    "\n",
    "__At the end, the data is very messy. Cleaning takes most of my time. Description seems to be a bad predictor in this case after all.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part 3: Pseudocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive baye\n",
    "\n",
    "Give training set X, with classes y where y can be multiple(eg: sport, art, tech):\n",
    "\n",
    "For each class y_i:\n",
    "2. Calculate number of elements in y_i / number of all elements in all class <= prior_i\n",
    "3. Find the word frequency <= f_i\n",
    "4. For each word x_i in X, calculate p(x_i | y_i) = f_i / y_i \n",
    "5. predict O: find P(y_i | O) = âˆ p(x_i | y_i)\n",
    "6. Label O based on the highest P(y_i | O). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BaseDiscreteNB\n",
    "class MultinomialNB(BaseDiscreteNB):\n",
    "    def __init__(self, alpha=1.0, fit_prior=True, class_prior=None):\n",
    "        self.alpha = alpha\n",
    "        self.fit_prior = fit_prior\n",
    "        self.class_prior = class_prior\n",
    "\n",
    "    def _count(self, X, Y):\n",
    "        \"\"\"Count and smooth feature occurrences.\"\"\"\n",
    "        # make sure X does not have negative values\n",
    "        if np.any((X.data if issparse(X) else X) < 0):\n",
    "            raise ValueError(\"Input X must be non-negative\")\n",
    "        # word frequency count for each feature\n",
    "        self.feature_count_ += safe_sparse_dot(Y.T, X)\n",
    "        # count classes\n",
    "        self.class_count_ += Y.sum(axis=0)\n",
    "\n",
    "    def _update_feature_log_prob(self):\n",
    "        \"\"\"Apply smoothing to raw counts and recompute log probabilities\"\"\"\n",
    "        \n",
    "        # Avoiding extremely low feature count\n",
    "        smoothed_fc = self.feature_count_ + self.alpha\n",
    "        smoothed_cc = smoothed_fc.sum(axis=1)\n",
    "        # np.log(f_i/y_i) >> np.log(f_i) - np.log(y_i)\n",
    "        self.feature_log_prob_ = (np.log(smoothed_fc) -\n",
    "                                  np.log(smoothed_cc.reshape(-1, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
